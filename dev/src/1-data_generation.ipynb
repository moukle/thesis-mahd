{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "import libs.automold.Automold as am\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Val Data generation\n",
    "## **1:** Load and augment sequences (rain + fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library.git libs/automold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.bit_generator = numpy.random._bit_generator # legacy _bit_generator used by imgaug...\n",
    "\n",
    "# different augs for day (more) / night (less)\n",
    "night_clouds_aug = iaa.CloudLayer(intensity_mean=(220, 255),\n",
    "            intensity_freq_exponent=(-2.0, -1.5),\n",
    "            intensity_coarse_scale=2,\n",
    "            alpha_min=(0.3, 0.5),\n",
    "            alpha_multiplier=0.3,\n",
    "            alpha_size_px_max=(2, 8),\n",
    "            alpha_freq_exponent=(-4.0, -2.0),\n",
    "            sparsity=0.9,\n",
    "            density_multiplier=(0.3, 0.4))\n",
    "\n",
    "\n",
    "day_clouds_aug = iaa.CloudLayer(intensity_mean=240,\n",
    "            intensity_freq_exponent=-2.0,\n",
    "            intensity_coarse_scale=2,\n",
    "            alpha_min=0.4,\n",
    "            alpha_multiplier=0.6,\n",
    "            alpha_size_px_max=2,\n",
    "            alpha_freq_exponent=-4.0,\n",
    "            sparsity=0.9,\n",
    "            density_multiplier=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iters = len(glob.glob(f'{c.sequences_dir}/*-orig/*.jpg'))*2\n",
    "with tqdm(total=total_iters) as pbar:\n",
    "    for sequence in glob.glob(f'{c.sequences_dir}/*-orig'):\n",
    "        rain_dir = f'{sequence[:-5]}-rain'\n",
    "        cloud_dir  = f'{sequence[:-5]}-fog'\n",
    "\n",
    "        if os.path.exists(cloud_dir): continue\n",
    "        os.makedirs(cloud_dir)\n",
    "\n",
    "        if os.path.exists(rain_dir): continue\n",
    "        os.makedirs(rain_dir)\n",
    "\n",
    "        for image_path in sorted(glob.glob(f'{sequence}/*.jpg')):\n",
    "            image = cv2.imread(image_path)\n",
    "            image_name = os.path.basename(image_path)\n",
    "\n",
    "            if \"night\" in sequence or \"dawn\" in sequence:\n",
    "                image_rain_path = os.path.join(rain_dir, image_name)\n",
    "                image_rain = am.add_rain(image, rain_type='heavy', slant=10)\n",
    "                cv2.imwrite(image_rain_path, image_rain)\n",
    "\n",
    "                image_clouds_path = os.path.join(cloud_dir, image_name)\n",
    "                image_clouds = night_clouds_aug.augment_image(image)\n",
    "                cv2.imwrite(image_clouds_path, image_clouds)\n",
    "            else:\n",
    "                image_rain_path = os.path.join(rain_dir, image_name)\n",
    "                image_rain = am.add_rain(image, rain_type='torrential')\n",
    "                cv2.imwrite(image_rain_path, image_rain)\n",
    "\n",
    "                image_clouds_path = os.path.join(cloud_dir, image_name)\n",
    "                image_clouds = day_clouds_aug.augment_image(image)\n",
    "                cv2.imwrite(image_clouds_path, image_clouds)\n",
    "                \n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do same for `test_sequenes`!\n",
    "- fog from automold being to harsh, thus use imgaug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iters = len(glob.glob(f'{c.test_sequences_dir}/*-orig/*.jpg'))*2\n",
    "with tqdm(total=total_iters) as pbar:\n",
    "    for sequence in glob.glob(f'{c.test_sequences_dir}/*-orig'):\n",
    "        rain_dir = f'{sequence[:-5]}-rain'\n",
    "        cloud_dir  = f'{sequence[:-5]}-fog'\n",
    "\n",
    "        if os.path.exists(cloud_dir) or os.path.exists(rain_dir):\n",
    "            pbar.update(len(glob.glob(f'{rain_dir}/*.jpg')))\n",
    "            pbar.update(len(glob.glob(f'{cloud_dir}/*.jpg')))\n",
    "            continue\n",
    "            \n",
    "        os.makedirs(cloud_dir)\n",
    "        os.makedirs(rain_dir)\n",
    "\n",
    "        for image_path in sorted(glob.glob(f'{sequence}/*.jpg')):\n",
    "            image = cv2.imread(image_path)\n",
    "            image_name = os.path.basename(image_path)\n",
    "\n",
    "            if \"night\" in sequence or \"dawn\" in sequence:\n",
    "                image_rain_path = os.path.join(rain_dir, image_name)\n",
    "                image_rain = am.add_rain(image, rain_type='heavy', slant=10)\n",
    "                cv2.imwrite(image_rain_path, image_rain)\n",
    "\n",
    "                image_clouds_path = os.path.join(cloud_dir, image_name)\n",
    "                image_clouds = night_clouds_aug.augment_image(image)\n",
    "                cv2.imwrite(image_clouds_path, image_clouds)\n",
    "            else:\n",
    "                image_rain_path = os.path.join(rain_dir, image_name)\n",
    "                image_rain = am.add_rain(image, rain_type='torrential')\n",
    "                cv2.imwrite(image_rain_path, image_rain)\n",
    "\n",
    "                image_clouds_path = os.path.join(cloud_dir, image_name)\n",
    "                image_clouds = day_clouds_aug.augment_image(image)\n",
    "                cv2.imwrite(image_clouds_path, image_clouds)\n",
    "                \n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2:** Extract ROIs for CNN training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmog import BMOG\n",
    "from roi_extractor import regions_of_interest\n",
    "\n",
    "total_iters = len(glob.glob(f'{c.sequences_dir}/*/*.jpg'))\n",
    "with tqdm(total=total_iters) as pbar:\n",
    "    for sequence in glob.glob(f'{c.sequences_dir}/*'):\n",
    "        seq_name = os.path.basename(sequence)\n",
    "        rois_dir = os.path.join(c.rois_dir, seq_name)\n",
    "\n",
    "        if os.path.exists(rois_dir): continue\n",
    "        os.makedirs(rois_dir)\n",
    "\n",
    "        bgs = BMOG(threshold_l=20, postprocessing_size=15)\n",
    "\n",
    "        for image_path in sorted(glob.glob(f'{sequence}/*.jpg'))[:c.frames_for_bgs_init]: bgs.apply(cv2.imread(image_path)) # initialize distributions\n",
    "        for image_path in sorted(glob.glob(f'{sequence}/*.jpg'))[c.frames_for_bgs_init:]:\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            fg_mask = bgs.apply(image)\n",
    "            fg_mask = cv2.dilate(fg_mask,(5,5), iterations=15)\n",
    "\n",
    "            rois = regions_of_interest(fg_mask , c.min_size, c.max_size, c.aspect_ratio)\n",
    "\n",
    "            for roi in rois:\n",
    "                x,y,x2,y2 = roi\n",
    "                roi_crop = image[y:y2, x:x2]\n",
    "                cv2.imwrite(f'{rois_dir}/{time.time()}.jpg', roi_crop)\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3:** Sort ROIs in classes **\"other\" & \"agriculture\"** ... _have fun_\n",
    "- create folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "for sequence in glob.glob(f'{c.rois_dir}/*'):\n",
    "    seq_name = os.path.basename(sequence)\n",
    "\n",
    "    for class_label in c.class_labels.values():\n",
    "        dir = os.path.join(c.rois_sorted_dir, seq_name, class_label)\n",
    "        if not os.path.exists(dir): os.makedirs(dir)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CNN to pre-sort ROIs _(for CNN see `2-fit_cnn_model.ipynb`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.efficientnet.efficientnet.tfkeras import preprocess_input\n",
    "import efn\n",
    "\n",
    "model = efn.build_model(phi=-5, dropout=0.15)\n",
    "model.load_weights(\"../output/old/efn_old/-5-dropout_0.15-up2/checkpoints/fit-gen_epoch-47_loss-0.18.hdf5\")\n",
    "image_shape = model.input_shape[1:3]\n",
    "\n",
    "total_amount_of_rois = len(glob.glob(f'{c.rois_dir}/*/*.jpg'))\n",
    "with tqdm(total=total_amount_of_rois) as pbar:\n",
    "    for sequence in glob.glob(f'{c.rois_dir}/*'):\n",
    "        seq_name = os.path.basename(sequence)\n",
    "        sorted_dir = os.path.join(c.rois_sorted_dir, seq_name)\n",
    "\n",
    "        if os.path.exists(sorted_dir): continue\n",
    "\n",
    "        for class_label in c.class_labels.values():\n",
    "            dir = os.path.join(c.rois_sorted_dir, seq_name, class_label)\n",
    "            os.makedirs(dir)\n",
    "\n",
    "        for image_path in glob.glob(f'{sequence}/*.jpg'):\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # prepare for predict\n",
    "            image_for_pred = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            image_for_pred = cv2.resize(image_for_pred, image_shape)\n",
    "            image_for_pred = np.expand_dims(image_for_pred, axis=0)\n",
    "            image_for_pred = preprocess_input(image_for_pred)\n",
    "            prediction = model.predict(image_for_pred)[0][0] > 0.5# predict and threshold\n",
    "\n",
    "            image_name = os.path.basename(image_path)\n",
    "            src = os.path.abspath(image_path)\n",
    "            dst = os.path.join(sorted_dir, c.class_labels[prediction], image_name)\n",
    "            #os.symlink(src, dst)\n",
    "            copyfile(src, dst)\n",
    "            \n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4:** Train / Val split\n",
    "- _test split is sorted out beforehand (extracted 3 original sequences)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agricultures = [agr for agr in glob.glob(c.rois_sorted_dir+\"/*/agriculture/*.jpg\")]\n",
    "all_others       = [other for other in glob.glob(c.rois_sorted_dir+\"/*/other/*.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = .75\n",
    "val_portion = .25\n",
    "\n",
    "train_size_agr = int(len(all_agricultures)*train_portion)\n",
    "train_size_other = int(len(all_others)*train_portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(all_agricultures)\n",
    "random.shuffle(all_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train split\n",
    "if not os.path.exists(c.train_dir):\n",
    "    for class_label in c.class_labels.values():\n",
    "        dir = os.path.join(c.train_dir, class_label)\n",
    "        if not os.path.exists(dir): os.makedirs(dir)\n",
    "    \n",
    "    for agr in all_agricultures[:train_size_agr]:\n",
    "        agr_name = os.path.basename(agr)\n",
    "        dst = os.path.join(c.train_dir, \"agriculture\", agr_name)\n",
    "        copyfile(agr, dst)\n",
    "\n",
    "    for other in all_others[:train_size_other]:\n",
    "        other_name = os.path.basename(other)\n",
    "        dst = os.path.join(c.train_dir, \"other\", other_name)\n",
    "        copyfile(other, dst)\n",
    "\n",
    "# val split\n",
    "if not os.path.exists(c.val_dir):\n",
    "    for class_label in c.class_labels.values():\n",
    "        dir = os.path.join(c.val_dir, class_label)\n",
    "        if not os.path.exists(dir): os.makedirs(dir)\n",
    "    \n",
    "    for agr in all_agricultures[train_size_agr:]:\n",
    "        agr_name = os.path.basename(agr)\n",
    "        dst = os.path.join(c.val_dir, \"agriculture\", agr_name)\n",
    "        copyfile(agr, dst)\n",
    "\n",
    "    for other in all_others[train_size_other:]:\n",
    "        other_name = os.path.basename(other)\n",
    "        dst = os.path.join(c.val_dir, \"other\", other_name)\n",
    "        copyfile(other, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance unweighted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes are very unbalanced\n",
    "print(\"Agriculutre (all, train, val) \\t\",\n",
    "      len(all_agricultures),\n",
    "      int(len(all_agricultures)*train_portion),\n",
    "      int(len(all_agricultures)*val_portion))\n",
    "\n",
    "print(\"Others (all, train, val) \\t\",\n",
    "      len(all_others),\n",
    "      int(len(all_others)*train_portion),\n",
    "      int(len(all_others)*val_portion))\n",
    "\n",
    "# thus augment minority class with factor X\n",
    "ratio = train_size_agr / train_size_other\n",
    "aug_factor = 1/ratio\n",
    "print(\"Ratio: \\t\\t\\t\\t\", aug_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment minority class (upsample) - 3 additional augmentations for minority class...\n",
    "import libs.automold.Automold as am\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import numpy\n",
    "#numpy.random.bit_generator = numpy.random._bit_generator\n",
    "\n",
    "aug = iaa.OneOf([\n",
    "    iaa.GaussianBlur((0, 3.0)),\n",
    "    iaa.ChannelShuffle(p=1.0),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.1*255)\n",
    "    ])\n",
    "\n",
    "os.makedirs(os.path.join(c.train_dir_up, \"agriculture\"))\n",
    "\n",
    "for agr in all_agricultures[:train_size_agr]:\n",
    "    agr_name = os.path.basename(agr)\n",
    "    dst = os.path.join(c.train_dir_up, \"agriculture\", agr_name)\n",
    "    copyfile(agr, dst)\n",
    "    \n",
    "    orig_img = cv2.imread(agr)\n",
    "    \n",
    "    aug_1 = am.darken(orig_img)\n",
    "    aug_2 = am.brighten(orig_img)\n",
    "    aug_3 = aug.augment_image(orig_img)\n",
    "    #aug_4 = chn.augment_image(orig_img)\n",
    "    #aug_5 = noise.augment_image(orig_img)\n",
    "    \n",
    "    cv2.imwrite(dst[:-4]+\"_aug_1.jpg\", aug_1)\n",
    "    cv2.imwrite(dst[:-4]+\"_aug_2.jpg\", aug_2)\n",
    "    cv2.imwrite(dst[:-4]+\"_aug_3.jpg\", aug_3)\n",
    "    #cv2.imwrite(dst[:-4]+\"_aug_4.jpg\", aug_4)\n",
    "    #cv2.imwrite(dst[:-4]+\"_aug_5.jpg\", aug_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# also copy majority class \n",
    "# should use symlink but creates difficulties for windows / docker usage\n",
    "copy_tree(os.path.join(c.train_dir, \"other\"), \n",
    "          os.path.join(c.train_dir_up, \"other\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
