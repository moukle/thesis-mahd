{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pylab import cm\n",
    "\n",
    "import constants as c\n",
    "\n",
    "from bmog import BMOG\n",
    "from roi_extractor import regions_of_interest\n",
    "\n",
    "from libs.efficientnet.efficientnet.tfkeras import preprocess_input\n",
    "import efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL AND WEIGHTS\n",
    "model = efn.build_model(phi=-5, dropout=0.15)\n",
    "model_checkpoints = \"../output/efn/-5-dropout_0.15-default/checkpoints/*.hdf5\"\n",
    "model.load_weights(max(glob.iglob(model_checkpoints), key=os.path.getctime))\n",
    "\n",
    "img_shape = model.input_shape[1:3]\n",
    "\n",
    "def inference(image):\n",
    "    img = cv2.resize(image, img_shape) # resize incoming image to models input shape\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # cv2 reads images in BGR, model is trained on RGB\n",
    "    img = np.expand_dims(img, axis=0) # model expects batches of images\n",
    "    img = preprocess_input(img) # apply preprocessing function (torch-normalization)\n",
    "    \n",
    "    return model.predict(img)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread_scaled(image_path, scale):\n",
    "    image = cv2.imread(image_path)\n",
    "    w,h,c = image.shape\n",
    "    w,h = int(w*scale), int(h*scale)\n",
    "    return cv2.resize(image, (h,w))\n",
    "\n",
    "def save_roi_pred(image_dir, bmog_threshold_l, bmog_postprocessing_size, dilation, min_size, init_frames, image_scale=1.0):\n",
    "    found_rois_at_config = {}\n",
    "\n",
    "    total_amount_iters = len(glob.glob(image_dir+\"/*/*.jpg\"))\n",
    "    with tqdm(total=total_amount_iters) as pbar:\n",
    "        for sequence in glob.glob(image_dir+\"/*\"):\n",
    "            seq_name = os.path.basename(sequence)\n",
    "            rois_for_sequence = {}\n",
    "\n",
    "            bgs = BMOG(threshold_l=bmog_threshold_l, postprocessing_size=bmog_postprocessing_size)\n",
    "\n",
    "            # initialize distributions\n",
    "            for image_path in sorted(glob.glob(f'{sequence}/*.jpg'))[:init_frames]: \n",
    "                bgs.apply(imread_scaled(image_path, image_scale)) \n",
    "                pbar.update()\n",
    "\n",
    "            # do roi extraction\n",
    "            for image_path in sorted(glob.glob(f'{sequence}/*.jpg'))[init_frames:]:\n",
    "                image_name = os.path.basename(image_path)[:-4] \n",
    "                image = imread_scaled(image_path, image_scale)\n",
    "\n",
    "                #image = cv2.medianBlur(image, blur_kernel)\n",
    "                fg_mask = bgs.apply(image)\n",
    "\n",
    "                if dilation:\n",
    "                    fg_mask = cv2.dilate(fg_mask,(5,5),\n",
    "                                        iterations=dilation)\n",
    "\n",
    "                rois = regions_of_interest(fg_mask,\n",
    "                                        min_size=min_size,\n",
    "                                        max_size=c.max_size*image_scale,\n",
    "                                        aspect_ratio=c.aspect_ratio)\n",
    "\n",
    "                rois_for_sequence[image_name] = []\n",
    "                for roi in rois:\n",
    "                    x,y,x2,y2 = roi\n",
    "                    roi_crop = image[y:y2, x:x2]\n",
    "                    p = inference(roi_crop)\n",
    "                    rois_for_sequence[image_name].append([x,y,x2,y2,p])\n",
    "                pbar.update()\n",
    "                #print(rois_for_sequence[image_name])\n",
    "            found_rois_at_config[seq_name] = rois_for_sequence\n",
    "    \n",
    "    \n",
    "    file_name = f'inference_scale-{image_scale}'\n",
    "    with open(f'{c.output_dir_inference}/{file_name}.pickle', 'wb') as handle:\n",
    "        pickle.dump(found_rois_at_config, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "\n",
    "def bbs_from_xml(xml):\n",
    "    x = xmltodict.parse(xml)\n",
    "    bbs = []\n",
    "    \n",
    "    if 'object' in x['annotation']:  # check for bbs in annoataion file\n",
    "        for obj in x['annotation']['object']:\n",
    "            if type(obj) == str: # only one obj in annotation\n",
    "                obj = x['annotation']['object']\n",
    "                bbs.append(extract_information(obj))\n",
    "                break\n",
    "            bbs.append(extract_information(obj))\n",
    "    return bbs\n",
    "\n",
    "def extract_information(xml_object):\n",
    "    bndbox = xml_object['bndbox']\n",
    "    bnd_box = [\n",
    "            int(bndbox['xmin']),\n",
    "            int(bndbox['ymin']),\n",
    "            int(bndbox['xmax']),\n",
    "            int(bndbox['ymax']),\n",
    "            xml_object['name'],\n",
    "            ]\n",
    "    return bnd_box\n",
    "    \n",
    "def get_annotations_from_dir(annotation_dir):\n",
    "    annotations = {}\n",
    "    for file in glob.glob(f'{annotation_dir}/*.xml'):\n",
    "        bbs = bbs_from_xml(open(file, 'rb'))\n",
    "        file_base_name = (os.path.basename(file)[:-4])\n",
    "        annotations[file_base_name] = bbs\n",
    "    return annotations\n",
    "\n",
    "\n",
    "gt_bbs = {}\n",
    "for sequence in glob.glob(f'{c.test_sequences_dir}/*'):\n",
    "    seq_name = os.path.basename(sequence)\n",
    "    annotation_dir = os.path.join(c.test_annotation_dir, seq_name.partition('-')[0])\n",
    "    \n",
    "    gt_bbs[seq_name] = get_annotations_from_dir(annotation_dir)\n",
    "\n",
    "with open(f'{c.output_dir_inference}/gt_bbs_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(gt_bbs, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_roi_pred(c.test_sequences_dir, bmog_threshold_l=20, bmog_postprocessing_size=15, dilation=15, min_size=15, init_frames=c.frames_for_bgs_init, image_scale=1.0) # default (no scale..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "\n",
    "def weird_division(n, d):\n",
    "    return n / d if d else 0\n",
    "\n",
    "\n",
    "def statistics_for_rois_pred(_found, _gt, iou_min, scale=1.0, threshold=0.5):\n",
    "    iou_min_day, iou_night = iou_min\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # get every sequence of GTs\n",
    "    for seq_name in _gt.keys():\n",
    "        if 'day' in seq_name:\n",
    "            iou_for_seq = iou_min_day\n",
    "        else:\n",
    "            iou_for_seq = iou_night\n",
    "            \n",
    "        \n",
    "        not_even_found = 0\n",
    "        should_have_been_found = 0\n",
    "        FOUND_IN_SEQ = 0\n",
    "        if seq_name in _found.keys():\n",
    "            not_even_found = 0\n",
    "            should_have_been_found = 0\n",
    "            FOUND_IN_SEQ = 0\n",
    "            \n",
    "            tps = 0\n",
    "            fns = 0\n",
    "            fps = 0\n",
    "            tn = 0\n",
    "\n",
    "            # check every prediction for each frame\n",
    "            for file_name, gts in _gt[seq_name].items():\n",
    "                if file_name in _found[seq_name]:\n",
    "                    for gt in gts:\n",
    "                        gt = np.array(np.array(gt[0:4])*scale, dtype=int)\n",
    "\n",
    "                        should_have_been_found += 1\n",
    "                        found_intersecting_bb = False\n",
    "\n",
    "                        # compare annotated roi with found rois, and stop when match is found\n",
    "                        for found in _found[seq_name][file_name]:\n",
    "                            iou = bb_intersection_over_union(gt, found)\n",
    "                            if iou > iou_for_seq:\n",
    "                                found_intersecting_bb = True\n",
    "                                \n",
    "                                if found[4] > threshold:\n",
    "                                    tps += 1\n",
    "                                else:\n",
    "                                    fns += 1\n",
    "\n",
    "                        if not found_intersecting_bb:\n",
    "                            fps += 1\n",
    "                            not_even_found += 1\n",
    "\n",
    "                    FOUND_IN_SEQ += len(_found[seq_name][file_name])\n",
    "        results[seq_name] = not_even_found, should_have_been_found, FOUND_IN_SEQ, tps, fns, fps\n",
    "        #results_scale[seq_name] = 20, 100, 120\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbs = {}\n",
    "pred_bbs = {}\n",
    "\n",
    "with open(f'{c.output_dir_inference}/gt_bbs_test.pickle', 'rb') as handle:\n",
    "    gt_bbs = pickle.load(handle)\n",
    "    \n",
    "with open(f'{c.output_dir_inference}/inference_scale-1.0.pickle', 'rb') as handle:\n",
    "    pred_bbs = pickle.load(handle)\n",
    "\n",
    "iou_min = [0.4, 0.3]\n",
    "statistics = statistics_for_rois_pred(pred_bbs, gt_bbs, iou_min, threshold=0.7)\n",
    "\n",
    "not_found = []\n",
    "total = []\n",
    "seqs = []\n",
    "been_found = []\n",
    "\n",
    "true_positives = []\n",
    "false_negatives = []\n",
    "false_positives = []\n",
    "\n",
    "\n",
    "n_seqs = len(gt_bbs.keys())\n",
    "\n",
    "for seq_name, res in sorted(statistics.items()):\n",
    "    not_found.append(res[0])\n",
    "    total.append(res[1])\n",
    "    been_found.append(res[2])\n",
    "\n",
    "    true_positives.append(res[3])\n",
    "    false_positives.append(res[5])\n",
    "    false_negatives.append(res[4])\n",
    "    \n",
    "    # beautify names\n",
    "    seq_name = seq_name.replace(\"_\", \" \").replace(\"-\", \" - \")[3:]\n",
    "    seq_name = seq_name.replace(\"day\", \"Tag\").replace(\"dawn\", \"Nacht\").replace(\"night\", \"Nacht\").replace(\"animals\", \"Tiere\")\n",
    "    seq_name = seq_name.replace(\"orig\", \"Original\").replace(\"fog\", \"Nebel\").replace(\"rain\", \"Regen\")\n",
    "    \n",
    "    seqs.append(seq_name)\n",
    "\n",
    "    \n",
    "true_negatives = np.subtract(been_found, \n",
    "                             np.array([true_positives, false_positives, false_negatives, not_found]).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.arange(len(seqs))\n",
    "bar_width = 0.9\n",
    "\n",
    "#plt.bar(pos, been_found, color='C7', width=1, alpha=0.3, label=\"Gefunden\")\n",
    "plt.bar(pos, total, color='C7', width=1, alpha=0.5, label=\"Gesucht\")\n",
    "\n",
    "\n",
    "cmap = cm.get_cmap('viridis', n_seqs*3)\n",
    "greens = [matplotlib.colors.rgb2hex(cmap(idx)[:3]) for idx in [22, 29]]\n",
    "\n",
    "reds = [matplotlib.colors.rgb2hex(cmap(idx)[:3]) for idx in [4, 10, 18]]\n",
    "\n",
    "my_cmap = []\n",
    "handles = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        idx = (i*9)+2*j\n",
    "        color = matplotlib.colors.rgb2hex(cmap(idx)[:3])\n",
    "        my_cmap.append(color)\n",
    "        handles.append(plt.Rectangle((0,0),1,1, color=color))\n",
    "\n",
    "# tps, tns, fps, fns, nf\n",
    "my_colors = [\"#86B300\",\n",
    "             \"#F29718\",\n",
    "             \"#EA6C6D\",\n",
    "             \"#46BA94\",\n",
    "             \"#3199E1\"]\n",
    "\n",
    "\n",
    "plt.bar(pos, not_found, color=my_colors[4], label=\"Nicht gefunden\")\n",
    "\n",
    "bottom = not_found\n",
    "plt.bar(pos, false_negatives, bottom=bottom, color=my_colors[3], label=\"False Negatives\")\n",
    "\n",
    "bottom = np.add(bottom, false_negatives)\n",
    "plt.bar(pos, true_positives, bottom=bottom, label=\"True Positives\", color=my_colors[0])\n",
    "\n",
    "bottom = np.add(bottom, true_positives)\n",
    "plt.bar(pos, false_positives, bottom=bottom, label=\"False Positives\", color=my_colors[2])\n",
    "\n",
    "bottom = np.add(bottom, false_positives)\n",
    "plt.bar(pos, true_negatives, bottom=bottom, label=\"True Negatives\", color=my_colors[1])\n",
    "\n",
    "\n",
    "#plt.plot(pos, been_found, label=\"Anzahl vorhergesagter ROIs\")\n",
    "\n",
    "\n",
    "#plt.title(f\"Inferenz - Confusion Bars\")\n",
    "plt.xticks([], [])\n",
    "plt.xlim(-0.5, n_seqs-0.5)\n",
    "#plt.ylim(0, 180)\n",
    "\n",
    "\"\"\"\n",
    "for p in ax.patches[n_seqs:]:\n",
    "    h = p.get_height()\n",
    "    x = p.get_x()+p.get_width()/2.\n",
    "    y = p.get_y()\n",
    "    if h != 0:\n",
    "        ax.annotate(\"%g\" % p.get_height(), xy=(x,y), xytext=(0,4), rotation=0, \n",
    "                   textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n",
    "\"\"\"\n",
    "plt.legend(\n",
    "            loc='upper center', bbox_to_anchor=(0.5, -0.02),\n",
    "            fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "plt.savefig(f\"../visuals/inference-cmbars.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives_true = np.add(false_negatives, not_found)\n",
    "\n",
    "recall = np.divide(true_positives, np.add(true_positives,false_positives))\n",
    "precision = np.divide(true_positives, np.add(true_positives,false_negatives_true))\n",
    "f1 = np.divide(np.multiply(np.multiply(precision, recall), 2), np.add(precision, recall))\n",
    "\n",
    "_r = sum(true_positives) / (sum(true_positives)+sum(false_positives))\n",
    "_p = sum(true_positives) / (sum(true_positives)+sum(false_negatives_true))\n",
    "_f1 = 2 * _r * _p / (_r + _p)\n",
    "\n",
    "total_r = round(_r*100,1)\n",
    "total_p = round(_p*100,1)\n",
    "total_f1 = round(_f1*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.title(\"F1 Score\")\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "\n",
    "pos = np.arange(len(gt_bbs.keys()))\n",
    "\n",
    "cmap = cm.get_cmap('viridis', n_seqs*3)\n",
    "my_cmap = []\n",
    "handles = []\n",
    "for i in range(3):\n",
    "    for j in range(1,4):\n",
    "        idx = (i*n_seqs)+2*j\n",
    "        color = matplotlib.colors.rgb2hex(cmap(idx)[:3])\n",
    "        my_cmap.append(color)\n",
    "        \n",
    "        handles.append(plt.Rectangle((0,0),1,1, color=color))\n",
    "\n",
    "#handles.append(plt.Line2D([0], [0], color=\"k\", lw=4))\n",
    "#handles.append(plt.Line2D([0], [0], color='k', ls=\"--\"))\n",
    "     \n",
    "avg = sum(not_found) / sum(total)\n",
    "avg_perc = round(np.average(not_found)/np.average(total)*100,1)\n",
    "avg_bar = avg * np.average(total)\n",
    "axs[0,0].bar(pos, total, color='k', width=1, alpha=0.2)\n",
    "axs[0,0].plot([-0.5, 8.5], [avg_bar, avg_bar], \"--\", color='k', lw=1)\n",
    "axs[0,0].bar(pos, not_found, color=my_cmap)\n",
    "axs[0,0].set_title(f\"Nicht Gefunden ({avg_perc}%)\")\n",
    "\n",
    "\n",
    "axs[0,1].bar(pos, f1, color=my_cmap)\n",
    "axs[0,1].plot([-0.5, 8.5], [_f1, _f1], \"--\", color='k', lw=1)\n",
    "axs[0,1].set_title(f\"F1 Score ({total_f1}%)\")\n",
    "axs[0,1].set_ylim(0, 1)\n",
    "\n",
    "\n",
    "axs[1,1].bar(pos, recall, color=my_cmap)\n",
    "axs[1,1].plot([-0.5, 8.5], [_r, _r], \"--\", color='k', lw=1)\n",
    "axs[1,1].set_title(f\"Recall ({total_r}%)\")\n",
    "axs[1,1].set_ylim(0, 1)\n",
    "\n",
    "\n",
    "axs[1,0].bar(pos, precision, color=my_cmap)\n",
    "axs[1,0].plot([-0.5, 8.5], [_p, _p], \"--\", color='k', lw=1)\n",
    "axs[1,0].set_title(f\"Precision ({total_p}%)\")\n",
    "axs[1,0].set_ylim(0, 1)\n",
    "\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    #ax.label_outer()\n",
    "    ax.set_xlim(-0.5, 8.5)\n",
    "    ax.set_xticklabels([], [])\n",
    "    \n",
    "    \"\"\"\n",
    "    for p in ax.patches[n_seqs:]:\n",
    "        h = p.get_height()\n",
    "        x = p.get_x()+p.get_width()/2.\n",
    "        if h != 0:\n",
    "            ax.annotate(\"%g\" % p.get_height(), xy=(x,h), xytext=(0,4), rotation=90, \n",
    "                       textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n",
    "    \"\"\"\n",
    "import itertools\n",
    "def flip(items, ncol):\n",
    "    return itertools.chain(*[items[i::ncol] for i in range(ncol)])\n",
    "\n",
    "#plt.xlim(0.4,9-0.5)\n",
    "\n",
    "plt.legend(handles, seqs,\n",
    "            loc='upper center', bbox_to_anchor=(-0.2, -0.05),\n",
    "            fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "plt.savefig(f\"../visuals/inference-metrics.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sequenz \\t\\t\\t\\t ROIs \\t gesucht \\t nicht gefunden \\t TPs \\t FPs \\t FNs \\t TNs\")\n",
    "\n",
    "for i in range(n_seqs):\n",
    "    print(seqs[i][:14],\n",
    "         f\"\\t\\t\\t\\t {been_found[i]} \\t {total[i]} \\t\\t {not_found[i]} \\t\\t\\t {true_positives[i]} \\t {false_positives[i]} \\t {false_negatives[i]} \\t {true_negatives[i]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different scales for `min-obj-size` determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessors = np.flip([13,13,11,9,7,7,5,5,5]) # must be odd, thus cannot simply scale them\n",
    "\n",
    "for scale, post in zip(np.around(np.linspace(0.1, 1, 9, endpoint=False), 1), postprocessors):\n",
    "        save_roi_pred(c.test_sequences_dir, bmog_threshold_l=20,\n",
    "                         bmog_postprocessing_size=post,\n",
    "                         dilation=post,\n",
    "                         min_size=post,\n",
    "                         init_frames=c.frames_for_bgs_init,\n",
    "                         image_scale=scale)\n",
    "# and move to 'output/bmog_scaling' + number them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/inference/gt_bbs_test.pickle', 'rb') as handle:\n",
    "    gt_bbs = pickle.load(handle)\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "ax_i = 0\n",
    "for iou_min in [[0.4, 0.3], [0.3, 0.2]]:\n",
    "\n",
    "    statics = {}\n",
    "    for rois_config_path in glob.glob(f\"../output/inference/inference_scale-*.pickle\"):\n",
    "        config_name = os.path.basename(rois_config_path)\n",
    "\n",
    "        # last param (-1), cut '.pickle', get number\n",
    "        scale = float(config_name.split('_')[-1][:-7].split('-')[-1])\n",
    "\n",
    "\n",
    "\n",
    "        with open(rois_config_path, 'rb') as handle:\n",
    "            found_rois = pickle.load(handle)\n",
    "            statics[config_name] = statistics_for_rois_pred(found_rois, gt_bbs, iou_min=iou_min, scale=scale)\n",
    "\n",
    "    SCALES = len(statics.keys())\n",
    "    SEQS = len(gt_bbs.keys())\n",
    "    i = 1\n",
    "\n",
    "    _found_amount = []\n",
    "    _not_found = []\n",
    "\n",
    "    for config_name in sorted(statics.keys())[:]:\n",
    "        not_found = []\n",
    "        total = []\n",
    "        seqs = []\n",
    "        been_found = []\n",
    "\n",
    "        for seq_name, res in sorted(statics[config_name].items()):\n",
    "            if res[1]:\n",
    "                not_found.append(res[0])\n",
    "                total.append(res[1])\n",
    "                been_found.append(res[-1])\n",
    "                seqs.append(seq_name)\n",
    "\n",
    "        pos = np.arange(len(seqs)*(i-1), len(seqs)*i)\n",
    "        bar_width = 0.9\n",
    "\n",
    "        label = config_name.replace(\"_\", \", \").replace(\"-\", \": \")[10:][:-7].title()\n",
    "\n",
    "        axs[ax_i].bar(pos, total, color='k', width=1, alpha=0.2, label=\"Gesuchte Traktoren\")\n",
    "        axs[ax_i].bar(pos, not_found, width=bar_width, alpha=0.9)#, label=label)\n",
    "        #plt.plot([pos[0],pos[-1]], [sum(not_found)/9, sum(not_found)/9], \"--\", color=f'C{i-1}', label=\"Insgesamt nicht gefunden\")\n",
    "        #plt.plot(pos, np.divide(been_found,1), \":\", label=\"Vorhergesagte ROIs\")\n",
    "\n",
    "        i +=1\n",
    "\n",
    "        _found_amount.append(sum(been_found))\n",
    "        _not_found.append(sum(not_found))\n",
    "\n",
    "\n",
    "    not_found_percent = np.multiply(np.divide(_not_found, sum(total)), 100)\n",
    "\n",
    "    pos = np.linspace(0, (SEQS-1)*SCALES, SCALES)+4\n",
    "    axs[ax_i].plot(pos, not_found_percent, \"o\", color=\"k\", label=\"% nicht gefunden\")\n",
    "\n",
    "    for i in range(SCALES):\n",
    "        axs[ax_i].annotate(f\"{round(not_found_percent[i], 1)}\", # this is the text\n",
    "                 (pos[i], not_found_percent[i]), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(5,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "\n",
    "    #plt.plot(np.arange(i-1)*SEQS+2.5, np.divide(_found_amount, 10), \":\", marker='o', markersize=3, color='k', label=\"Insgesamt vorhergesagte ROIs / 10\", lw=1)\n",
    "\n",
    "    #plt.title(f\"BGS - Bildskalierung\")\n",
    "    axs[ax_i].set_xticks(np.linspace(4, 84, 10))\n",
    "    axs[ax_i].set_xticklabels(np.linspace(10, 100, 10, dtype=int))\n",
    "    axs[ax_i].set_xlabel(\"Skalierung\")\n",
    "    \n",
    "    axs[ax_i].set_title(f\"IoU - Tag {iou_min[0]} & Nacht {iou_min[1]}\")\n",
    "    \n",
    "    axs[ax_i].set_ylim(0, 150)\n",
    "    axs[ax_i].set_xlim(-1, SCALES*SEQS)\n",
    "\n",
    "    #axs[ax_i].set_grid(axis='y', alpha=0.2, linestyle=\"-\")\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(labels, handles))\n",
    "\n",
    "    plt.legend(by_label.values(), by_label.keys(),\n",
    "                loc='upper center', bbox_to_anchor=(0.5, -0.35),\n",
    "                fancybox=True, shadow=True, ncol=4)\n",
    "\n",
    "    leg = ax.get_legend()\n",
    "    #leg.legendHandles[0].set_color('C7')\n",
    "    #leg.legendHandles[1].set_color('C7')\n",
    "    \n",
    "    ax_i +=1\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.savefig(f\"../visuals/bgs-scaling.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/inference/gt_bbs_test.pickle', 'rb') as handle:\n",
    "    gt_bbs = pickle.load(handle)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "ax_i = 0\n",
    "for iou_min in [[0.4, 0.3], [0.3, 0.2]]:\n",
    "\n",
    "    statics = {}\n",
    "    for rois_config_path in glob.glob(f\"../output/inference/inference_scale-*.pickle\"):\n",
    "        config_name = os.path.basename(rois_config_path)\n",
    "\n",
    "        # last param (-1), cut '.pickle', get number\n",
    "        scale = float(config_name.split('_')[-1][:-7].split('-')[-1])\n",
    "\n",
    "\n",
    "\n",
    "        with open(rois_config_path, 'rb') as handle:\n",
    "            found_rois = pickle.load(handle)\n",
    "            statics[config_name] = statistics_for_rois_pred(found_rois, gt_bbs, iou_min=iou_min, scale=scale)\n",
    "\n",
    "    SCALES = len(statics.keys())\n",
    "    SEQS = len(gt_bbs.keys())\n",
    "    i = 1\n",
    "\n",
    "    _found_amount = []\n",
    "    _not_found = []\n",
    "\n",
    "    for config_name in sorted(statics.keys())[:]:\n",
    "        not_found = []\n",
    "        total = []\n",
    "        seqs = []\n",
    "        been_found = []\n",
    "\n",
    "        for seq_name, res in sorted(statics[config_name].items()):\n",
    "            if res[1]:\n",
    "                not_found.append(res[0])\n",
    "                total.append(res[1])\n",
    "                been_found.append(res[-1])\n",
    "                seqs.append(seq_name)\n",
    "\n",
    "        pos = np.arange(len(seqs)*(i-1), len(seqs)*i)\n",
    "        bar_width = 0.9\n",
    "\n",
    "        label = config_name.replace(\"_\", \", \").replace(\"-\", \": \")[10:][:-7].title()\n",
    "\n",
    "        axs[ax_i].bar(pos, total, color='k', width=1, alpha=0.2, label=\"Gesuchte Traktoren\")\n",
    "        axs[ax_i].bar(pos, not_found, label=label, width=bar_width, alpha=0.9)\n",
    "        #plt.plot([pos[0],pos[-1]], [sum(not_found)/9, sum(not_found)/9], \"--\", color=f'C{i-1}', label=\"Insgesamt nicht gefunden\")\n",
    "        #plt.plot(pos, np.divide(been_found,1), \":\", label=\"Vorhergesagte ROIs\")\n",
    "\n",
    "        i +=1\n",
    "\n",
    "        _found_amount.append(sum(been_found))\n",
    "        _not_found.append(sum(not_found))\n",
    "\n",
    "\n",
    "    not_found_percent = np.multiply(np.divide(_not_found, sum(total)), 100)\n",
    "\n",
    "    pos = np.linspace(0, (SEQS-1)*SCALES, SCALES)+SEQS/3\n",
    "    axs[ax_i].plot(pos, not_found_percent, \"o-\", color=\"k\", label=\"% nicht gefunden\")\n",
    "\n",
    "    for i in range(SCALES):\n",
    "        axs[ax_i].annotate(f\"{round(not_found_percent[i], 1)}\", # this is the text\n",
    "                 (pos[i], not_found_percent[i]), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(5,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "\n",
    "    #plt.plot(np.arange(i-1)*SEQS+2.5, np.divide(_found_amount, 10), \":\", marker='o', markersize=3, color='k', label=\"Insgesamt vorhergesagte ROIs / 10\", lw=1)\n",
    "\n",
    "    #plt.title(f\"BGS - Bildskalierung\")\n",
    "    axs[ax_i].set_xticklabels(np.around(np.linspace(0, 1, 5), 1))\n",
    "    \n",
    "    axs[ax_i].set_ylim(0, 150)\n",
    "    axs[ax_i].set_xlim(-1, SCALES*SEQS)\n",
    "\n",
    "    #axs[ax_i].set_grid(axis='y', alpha=0.2, linestyle=\"-\")\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = OrderedDict(zip(labels, handles))\n",
    "\n",
    "    plt.legend(by_label.values(), by_label.keys(),\n",
    "                loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "                fancybox=True, shadow=True, ncol=4)\n",
    "\n",
    "    leg = ax.get_legend()\n",
    "    #leg.legendHandles[0].set_color('C7')\n",
    "    #leg.legendHandles[1].set_color('C7')\n",
    "    \n",
    "    ax_i +=1\n",
    "\n",
    "#plt.savefig(f\"../visuals/bgs-scaling-big-iou.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/inference/gt_bbs_test.pickle', 'rb') as handle:\n",
    "    gt_bbs = pickle.load(handle)\n",
    "\n",
    "\n",
    "iou_min = [0.4, 0.2]\n",
    "\n",
    "\n",
    "\n",
    "for rois_config_path in glob.glob(f\"../output/inference/inference_scale-*.pickle\"):\n",
    "    config_name = os.path.basename(rois_config_path)\n",
    "    \n",
    "    # last param (-1), cut '.pickle', get number\n",
    "    scale = float(config_name.split('_')[-1][:-7].split('-')[-1])\n",
    "    \n",
    "    with open(rois_config_path, 'rb') as handle:\n",
    "        found_rois = pickle.load(handle)\n",
    "        statistics = statistics_for_rois_pred(found_rois, gt_bbs, iou_min=iou_min, scale=scale)\n",
    "\n",
    "        not_found = 0\n",
    "        total = 0\n",
    "        seqs = 0\n",
    "        been_found = 0\n",
    "\n",
    "        true_positives = 0\n",
    "        false_negatives = 0\n",
    "        false_positives = 0\n",
    "\n",
    "        n_seqs = len(gt_bbs.keys())\n",
    "\n",
    "        for seq_name, res in sorted(statistics.items()):\n",
    "            not_found += res[0]\n",
    "            total += res[1]\n",
    "            been_found += res[2]\n",
    "\n",
    "            true_positives += res[3]\n",
    "            false_positives += res[5]\n",
    "            false_negatives += res[4]\n",
    "        true_negatives = been_found - true_positives - false_positives - false_negatives - not_found\n",
    "        \n",
    "        \n",
    "        recall = true_positives / (true_positives+(false_negatives+not_found))\n",
    "        precision = true_positives / (true_positives+false_positives)\n",
    "        f1 = 2*recall*precision / (recall+precision)\n",
    "        \n",
    "        # tps, tns, fps, fns, nf\n",
    "        my_colors = [\"#86B300\",\n",
    "             \"#F29718\",\n",
    "             \"#EA6C6D\",\n",
    "             \"#46BA94\",\n",
    "             \"#3199E1\"]\n",
    "        \n",
    "        plt.bar(scale, total, color='C7', width=0.1, alpha=0.4, label=\"Gesucht\")\n",
    "        \n",
    "        plt.bar(scale, not_found, color=my_colors[4], label=\"Nicht gefunden\", width=0.05)\n",
    "\n",
    "        bottom = not_found\n",
    "        plt.bar(scale, false_negatives, bottom=bottom, color=my_colors[3], label=\"False Negatives\", width=0.05)\n",
    "\n",
    "        bottom = np.add(bottom, false_negatives)\n",
    "        plt.bar(scale, true_positives, bottom=bottom, label=\"True Positives\", color=my_colors[0], width=0.05)\n",
    "\n",
    "        bottom = np.add(bottom, true_positives)\n",
    "        plt.bar(scale, false_positives, bottom=bottom, label=\"False Positives\", color=my_colors[2], width=0.05)\n",
    "\n",
    "        bottom = np.add(bottom, false_positives)\n",
    "        plt.bar(scale, true_negatives, bottom=bottom, label=\"True Negatives\", color=my_colors[1], width=0.05)\n",
    "        \n",
    "        TOTAL = bottom+true_negatives\n",
    "        plt.plot(scale, f1*2300, \"o\", color=\"k\", label=f\"F1 Score\")\n",
    "        \n",
    "        \n",
    "        plt.annotate(f\"{round(f1*100)}\", # this is the text\n",
    "                 (scale,f1*2300), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "plt.xlabel(\"Scale\")\n",
    "plt.ylim(0, 2500)\n",
    "plt.xlim(0.05, 1.05)\n",
    "plt.xticks(np.linspace(0.1, 1, 10))\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = OrderedDict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),\n",
    "    loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "    fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw IoUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ious(image, gt, pred, iou):\n",
    "    gt_color = (255,0,0)\n",
    "    pred_color = (0, 255, 0)\n",
    "    text_color = (255, 255, 0)\n",
    "    linewidth = 2\n",
    "    \n",
    "    cv2.rectangle(image, tuple(gt[:2]), tuple(gt[2:]), gt_color, linewidth)\n",
    "    cv2.rectangle(image, tuple(pred[:2]), tuple(pred[2:]), pred_color, linewidth)\n",
    "    \n",
    "    cv2.putText(image, \"IoU: {:.4f}\".format(iou), tuple(gt[:2]),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def find_best_ious(image_dir, out_dir, gts, preds, scale):\n",
    "    for seq_name in gts.keys():\n",
    "\n",
    "        seq_dir = os.path.join(image_dir, seq_name)\n",
    "        img_out_dir = os.path.join(out_dir, seq_name)\n",
    "        os.makedirs(img_out_dir)\n",
    "\n",
    "        for image_name in gts[seq_name].keys():\n",
    "            image_path = f\"{seq_dir}/{image_name}.jpg\"\n",
    "            img = imread_scaled(image_path, scale)\n",
    "            \n",
    "            for gt in gts[seq_name][image_name]:\n",
    "                if not image_name in preds[seq_name]: break # most likely been used for BGS init\n",
    "                \n",
    "                gt = np.array(np.array(gt[0:4])*scale, dtype=int)\n",
    "                best_iou = 0\n",
    "                best_pred = [0,0,0,0]\n",
    "                \n",
    "                for pred in preds[seq_name][image_name]:\n",
    "                    iou = bb_intersection_over_union(gt, pred)\n",
    "                    \n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_pred = pred[:4]\n",
    "                img = draw_ious(img, gt, best_pred, best_iou)\n",
    "            \n",
    "            cv2.imwrite(f\"{img_out_dir}/{image_name}.jpg\", img)\n",
    "            \n",
    "            \n",
    "def find_ious2(image_dir, out_dir, gts, preds, scale):\n",
    "    iou_min_day, iou_night = 0.4, 0.3\n",
    "\n",
    "    for seq_name in gts.keys():\n",
    "        \n",
    "        if 'day' in seq_name:\n",
    "            min_iou_for_seq = iou_min_day\n",
    "        else:\n",
    "            min_iou_for_seq = iou_night\n",
    "            \n",
    "        seq_dir = os.path.join(image_dir, seq_name)\n",
    "        img_out_dir = os.path.join(out_dir, seq_name)\n",
    "        os.makedirs(img_out_dir)\n",
    "\n",
    "        for image_name in gts[seq_name].keys():\n",
    "            image_path = f\"{seq_dir}/{image_name}.jpg\"\n",
    "            img = imread_scaled(image_path, scale)\n",
    "            \n",
    "            drawn = False\n",
    "            if not image_name in preds[seq_name]: break # most likely been used for BGS init\n",
    "            for pred in preds[seq_name][image_name]:\n",
    "                best_iou = 0\n",
    "                threshold = 0.7\n",
    "                \n",
    "                \n",
    "                if pred[4] > threshold:\n",
    "                    for gt in gts[seq_name][image_name]:\n",
    "                        gt = np.array(np.array(gt[0:4])*scale, dtype=int)\n",
    "                        iou = bb_intersection_over_union(gt, pred)\n",
    "\n",
    "                        if iou > best_iou:\n",
    "                            best_iou = iou\n",
    "\n",
    "                    if best_iou < min_iou_for_seq and pred[4] > threshold:\n",
    "                        img = draw_ious(img, gt, pred[:4], iou)\n",
    "                        drawn = True\n",
    "\n",
    "            if drawn:\n",
    "                cv2.imwrite(f\"{img_out_dir}/{image_name}.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rois_config_path in glob.glob(f\"../output/inference/inference_scale-*.pickle\"):\n",
    "    config_name = os.path.basename(rois_config_path)\n",
    "    \n",
    "    # last param (-1), cut '.pickle', get number\n",
    "    scale = float(config_name.split('_')[-1][:-7].split('-')[-1])\n",
    "    print(scale)\n",
    "    \n",
    "    with open(rois_config_path, 'rb') as handle:\n",
    "        preds = pickle.load(handle)\n",
    "        \n",
    "        out_dir = f\"../visuals/ious/inf_scale-{scale}\"\n",
    "        find_ious2(c.test_sequences_dir, out_dir, gt_bbs, preds, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE ON LOW SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL AND WEIGHTS\n",
    "model = efn.build_model(phi=-15, dropout=0.15)\n",
    "#model_checkpoints = \"../output/efn/-5-dropout_0.15-weighted/checkpoints/*.hdf5\"\n",
    "model_checkpoints = \"../output/efn_scale/-15-dropout_0.05-weighted/checkpoints/*.hdf5\"\n",
    "model.load_weights(max(glob.iglob(model_checkpoints), key=os.path.getctime))\n",
    "\n",
    "img_shape = model.input_shape[1:3]\n",
    "\n",
    "def inference(image):\n",
    "    img = cv2.resize(image, img_shape) # resize incoming image to models input shape\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # cv2 reads images in BGR, model is trained on RGB\n",
    "    img = np.expand_dims(img, axis=0) # model expects batches of images\n",
    "    img = preprocess_input(img) # apply preprocessing function (torch-normalization)\n",
    "    \n",
    "    return model.predict(img)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_roi_pred(c.test_sequences_dir,\n",
    "              bmog_threshold_l=20, bmog_postprocessing_size=7,\n",
    "              dilation=7, min_size=7,\n",
    "              init_frames=c.frames_for_bgs_init, image_scale=0.5) # default (no scale..)\n",
    "\n",
    "\n",
    "\n",
    "# -> rename and plot!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
